{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ερώτηση 3 (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 2.2121810913085938 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time \n",
    "\n",
    "yelp_dataset_path = '../yelp-dataset/'\n",
    "buisness_v_path = yelp_dataset_path + 'yelp_academic_dataset_business.json'\n",
    "leftK_path = '/home/left/Desktop/dataMining/set2/ask2/yelp_academic_dataset_business.json'\n",
    "\n",
    "dataset_business = []\n",
    "categories_order = [\"Beauty & Spas\", \"Shopping\", \"Bars\"]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with open(leftK_path, 'r', encoding=\"utf8\") as buisness_file:\n",
    "    for line in buisness_file:\n",
    "        json_dict = json.loads(line)\n",
    "        if  json_dict['city'] == 'Toronto' and \\\n",
    "            json_dict['review_count'] > 10 and \\\n",
    "            json_dict['categories'] is not None and \\\n",
    "            any(word in json_dict['categories'] for word in categories_order):\n",
    "                temp_cat = [cat for cat in categories_order if cat in json_dict['categories']][0]\n",
    "                dataset_business.append([json_dict['business_id'], temp_cat])\n",
    "                \n",
    "\n",
    "stop = time.time()\n",
    "print(\"Read file in {} seconds\".format(stop-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3265"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_business = np.array(dataset_business)\n",
    "np_business_id = np_business[:,0]\n",
    "len(np_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(business_id):\n",
    "    index = np.where(np_business_id == business_id)[0]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 5.425297764937083 mins\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "business_review_txt = [[] for i in range(int(len(np_business)))]\n",
    "review_v_path = yelp_dataset_path + 'yelp_academic_dataset_review.json'\n",
    "leftK_path = '/home/left/Desktop/dataMining/set2/ask2/yelp_academic_dataset_review.json'\n",
    "\n",
    "with open(leftK_path, 'r', encoding=\"utf8\") as reviews_file:\n",
    "    for line in reviews_file:\n",
    "        json_dict = json.loads(line)\n",
    "        index = get_index(json_dict['business_id'])\n",
    "\n",
    "        if index.size > 0:\n",
    "            if len(business_review_txt[index[0]]) == 0:\n",
    "                business_review_txt[index[0]] = json_dict['text']\n",
    "            else:\n",
    "                business_review_txt[index[0]] += json_dict['text']\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print(\"Read file in {} mins\".format((stop-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "fitted_vectorizer = tfidf.fit_transform(business_review_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import sklearn.cluster as sk_cluster\n",
    "import sklearn.metrics as metrics\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "kmeans = sk_cluster.KMeans(n_clusters=3)\n",
    "predictions = kmeans.fit_predict(fitted_vectorizer)\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "#p = metrics.precision_score(true_labels, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np_business[:,1]\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i]=='Bars':\n",
    "        true_labels[i]=0\n",
    "    if true_labels[i]=='Beauty & Spas':\n",
    "        true_labels[i]=1\n",
    "    if true_labels[i]=='Shopping':\n",
    "        true_labels[i]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '1', ..., '0', '0', '0'], dtype='<U22')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
