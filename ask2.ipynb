{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../yelp-dataset/yelp_academic_dataset_business.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../yelp-dataset/yelp_academic_dataset_business.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-37522109e6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m data = [json.loads(line) for line in \n\u001b[0;32m----> 9\u001b[0;31m         open(yelp_dataset_path+'yelp_academic_dataset_business.json', 'r', encoding=\"utf8\")]\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../yelp-dataset/yelp_academic_dataset_business.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# Place Yelp dataset in ../yelp-dataset\n",
    "yelp_dataset_path = '../yelp-dataset/'\n",
    "print(yelp_dataset_path + 'yelp_academic_dataset_business.json')\n",
    "\n",
    "data = [json.loads(line) for line in \n",
    "        open(yelp_dataset_path+'yelp_academic_dataset_business.json', 'r', encoding=\"utf8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [x for x in data if x['city']=='Toronto']\n",
    "data = np.array(data) # Convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519692"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tor_total_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = np.array(tor_total_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(tor_total_business)):\n",
    "    test.append(tor_total_business[i]['user_id'])\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(test, return_counts=True)\n",
    "ok =dict(zip(unique, counts))\n",
    "final_l = []\n",
    "recs=0\n",
    "for i in range(len(counts)):\n",
    "    if counts[i]>=15:\n",
    "        final_l.append(unique[i])\n",
    "        recs += counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_l = np.array(final_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"review_id\":\"xQY8N_XvtGbearJ5X4QryQ\",\"user_id\":\"OwjRMXRC0KyPrIlcjaXeFQ\",\"business_id\":\"-MhfebM0QIsKt87iDN-FNw\",\"stars\":2.0,\"useful\":5,\"funny\":0,\"cool\":0,\"text\":\"As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\\\n\\\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It\\'s what real estate agents would call \\\\\"cozy\\\\\" or \\\\\"charming\\\\\" - basically any euphemism for small.\\\\n\\\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\\\n\\\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\\\n* it\\'s not kid friendly at all. Seriously, don\\'t bring them.\\\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \\\\\"just look around\\\\\" and \\\\\"do whatever.\\\\\" \\\\n\\\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.\",\"date\":\"2015-04-15 05:21:16\"}\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(yelp_dataset_path + 'yelp_academic_dataset_review.json') as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βημα 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_id             business_id  rating\n",
      "0       TZQSUDDcA4ek5gBd6BzcjA  qUWqjjjfpB2-4P3He5rsKw     4.0\n",
      "1       TZQSUDDcA4ek5gBd6BzcjA  6n_MDeYxU1ihB38be9TkVA     4.0\n",
      "2       TZQSUDDcA4ek5gBd6BzcjA  jo4KmAqlZ7vxjHIP7IIkAw     5.0\n",
      "3       TZQSUDDcA4ek5gBd6BzcjA  dsAcgF6qtZy2m6d_yWCrGQ     4.0\n",
      "4       TZQSUDDcA4ek5gBd6BzcjA  siaRCT2-PkyeXUVKrywcTg     4.0\n",
      "...                        ...                     ...     ...\n",
      "197107  3L3CI2Om_2SE3T6hxrJKPQ  j_hB9Gt3VMJAbA2JyvyFjw     4.0\n",
      "197108  3L3CI2Om_2SE3T6hxrJKPQ  WKcVegcUjAld1S737a_QHw     4.0\n",
      "197109  3L3CI2Om_2SE3T6hxrJKPQ  1FL3oE2mqq_EFAYPd1TWUg     5.0\n",
      "197110  3L3CI2Om_2SE3T6hxrJKPQ  hlrZHM4D48XiQtXh6cRg_w     1.0\n",
      "197111  3L3CI2Om_2SE3T6hxrJKPQ  _cVCzKQGt23KKW1M07Yvkw     5.0\n",
      "\n",
      "[197112 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "table_R = pd.read_csv(\"pruned_data.csv\", header = None)\n",
    "new_header = ['user_id', 'business_id', 'rating']\n",
    "table_R.columns = new_header[:]\n",
    "print(table_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data should have 9856 rows \n",
      "\n",
      "9856\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample data should have {} rows \\n\".format(math.ceil(len(table_R)*0.05)))\n",
    "sample_data = table_R.sample(frac=0.05)\n",
    "print(len(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 51154,  67783,  87856, 179066,  54674,   7530,  99140, 185321,\n",
      "             55584, 136820,\n",
      "            ...\n",
      "            145802,  30990,  21538, 160231,  15190,   4607, 116507,  18895,\n",
      "            189290, 151380],\n",
      "           dtype='int64', length=9856)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/left/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.index) # sampled indexes\n",
    "\n",
    "# Setting sample ratings to Nan\n",
    "for index in sample_data.index:\n",
    "    table_R['rating'].iloc[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableR = table_R.to_numpy()\n",
    "unique_users, countsU = np.unique(tableR[:,0], return_counts=True)\n",
    "unique_business, countsB = np.unique(tableR[:,1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_array = np.zeros((len(unique_users), len(unique_business)))\n",
    "# Create the sparse_array\n",
    "for i in range(len(unique_users)):\n",
    "    business_index = np.where( unique_users[i] == table_R['user_id'])\n",
    "    \n",
    "    for j in range(len(business_index[0])):\n",
    "        temp_business = table_R['business_id'][business_index[0][j]] #take business_id for given index\n",
    "        unique_business_ind = np.where(temp_business == unique_business)\n",
    "        sparse_array[i][unique_business_ind[0][0]] = table_R['rating'][business_index[0][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc = 0\n",
    "#for i in range(sparse_array.shape[0]):\n",
    "#    for j in range(sparse_array.shape[1]):\n",
    "#        if not math.isnan(sparse_array[i][j]):\n",
    "#            cc+=sparse_array[i][j]\n",
    "#cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βημα 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "spars = np.nan_to_num(sparse_array) # Change nan values from sparse_array to zero\n",
    "similarities = cosine_similarity(spars)\n",
    "sample_array = sample_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(user_id):\n",
    "    ind = np.where(user_id  == unique_users)\n",
    "    return ind[0][0]\n",
    "def find_business(business_id):\n",
    "    ind = np.where(business_id == unique_business)\n",
    "    return ind[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similarities(user1, common_users, ratings):\n",
    "    user_ind1 = find_index(user1)\n",
    "    similar = []\n",
    "    for i in range(len(common_users)):\n",
    "        temp_ind = find_index(common_users[i])\n",
    "        similar.append([common_users[i], float(similarities[user_ind1][temp_ind]), int(ratings[i])])\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UFC_prediction(similarity, rating):\n",
    "    numerator = 0\n",
    "    denominator = np.sum(similarity)\n",
    "    for i in range(len(similarity)):\n",
    "        numerator += similarity[i]*rating[i]\n",
    "    return numerator/denominator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "predictions = []\n",
    "for i in range(sample_array.shape[0]): # For every pair (u,b) that have missing rating\n",
    "    common_ratings = []\n",
    "    common_users = []\n",
    "    business_index = find_business(sample_array[i][1]) # Get business index\n",
    "    common_users_indexes = np.nonzero(spars[:,business_index]) # FIND INDEXES FOR NONZERO VALUES ONLY!\n",
    "    for j in range(len(common_users_indexes[0])): # For every row in spars- (Actually for every user)\n",
    "        common_ratings.append(spars[common_users_indexes[0][j]][business_index]) # Append ratings\n",
    "        common_users.append(unique_users[common_users_indexes[0][j]]) # Append the user_id\n",
    "    \n",
    "    most_k_similar_users = get_top_similarities(sample_array[i][0], common_users, common_ratings)\n",
    "    \n",
    "    vectors = np.array(sorted(most_k_similar_users, key=itemgetter(1), reverse=True))\n",
    "    vectors = vectors[:5]\n",
    "    vectors # user_id, similarity and rating for most k-similar users\n",
    "    similarity_vector = vectors[:,1].astype(float)\n",
    "    ratings_vector = vectors[:,2].astype(int)\n",
    "    prediction = UFC_prediction(similarity_vector, ratings_vector)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., ..., 5., 4., 4.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ratings = sample_data['rating']\n",
    "true_ratings = true_ratings.to_numpy()\n",
    "true_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.78649726, 3.85861815, 3.61068484, ..., 4.35505778, 4.07481429,\n",
       "       3.67921835])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = np.array(predictions)\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8319098462271004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences = abs(true_ratings - predicted_ratings)\n",
    "np.mean(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βημα 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transposed sparse array and similiarities between businesses\n",
    "transposed_sparse = np.transpose(spars)\n",
    "transposed_sparse.shape\n",
    "business_similarities = cosine_similarity(transposed_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similarities_business(business1, common_businesses, ratings):\n",
    "    business_ind1 = find_business(business1)\n",
    "    similar = []\n",
    "    for i in range(len(common_businesses)):\n",
    "        temp_ind = find_business(common_businesses[i])\n",
    "        similar.append([common_businesses[i], float(business_similarities[business_ind1][temp_ind]), int(ratings[i])])\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "predictions = []\n",
    "for i in range(sample_array.shape[0]): # For every pair (u,b) that have missing rating\n",
    "    common_ratings = []\n",
    "    common_businesses = []\n",
    "    user_index = find_index(sample_array[i][0]) # Get user index\n",
    "    common_business_indexes = np.nonzero(spars[user_index,:]) # FIND BUSINESSES INDEXES FOR NONZERO VALUES ONLY!\n",
    "    \n",
    "    for j in range(len(common_business_indexes[0])): # For every row in spars- (Actually for every rated business)\n",
    "        common_ratings.append(transposed_sparse[common_business_indexes[0][j]][user_index]) # Append ratings\n",
    "        common_businesses.append(unique_business[common_business_indexes[0][j]]) # Append the user_id\n",
    "    \n",
    "    most_k_similar_users = get_top_similarities_business(sample_array[i][1], common_businesses, common_ratings)\n",
    "    \n",
    "    vectors = np.array(sorted(most_k_similar_users, key=itemgetter(1), reverse=True))\n",
    "    vectors = vectors[:5]\n",
    "    vectors # user_id, similarity and rating for most k-similar users\n",
    "    similarity_vector = vectors[:,1].astype(float)\n",
    "    ratings_vector = vectors[:,2].astype(int)\n",
    "    prediction = UFC_prediction(similarity_vector, ratings_vector)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., ..., 5., 4., 4.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ratings = sample_data['rating']\n",
    "true_ratings = true_ratings.to_numpy()\n",
    "true_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.73830196, 3.99023806, 3.71560283, ..., 3.86936051, 3.57172889,\n",
       "       3.61509518])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = np.array(predictions)\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842694253630994"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences = abs(true_ratings - predicted_ratings)\n",
    "np.mean(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
